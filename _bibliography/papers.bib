---
---

@string{aps = {American Physical Society,}}

@inproceedings{webnlg2023,
    abbr={SIGDIAL/INLG},
    title = "The 2023 WebNLG Shared Task on Low Resource Languages Overview and Evaluation Results ({W}eb{NLG} 2023)",
    author = "Cripwell, Liam  and
      Belz, Anya  and
      Gardent, Claire  and
      Gatt, Albert  and
      Borg, Claudia  and
      Borg, Marthese  and
      Judge, John  and
      Lorandi, Michela  and
      Nikiforovskaya, Anna  and
      Soto-Martinez, William  and
      Thompson, Craig",
    year = "2023",
    booktitle = "(To Appear) Proceedings of the 1st Workshop on Muiltimodal, Multilingual Natural Language Generation (MM-NLG)",
    url = "https://synalp.gitlabpages.inria.fr/webnlg-challenge/webnlg_2023_report.pdf",
    pdf = "https://synalp.gitlabpages.inria.fr/webnlg-challenge/webnlg_2023_report.pdf",
    selected={true},
}

@inproceedings{cripwell-etal-2023-context,
    abbr={ACL},
    title = "Context-Aware Document Simplification",
    author = {Cripwell, Liam  and
      Legrand, Jo{\"e}l  and
      Gardent, Claire},
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.834",
    html = "https://aclanthology.org/2023.findings-acl.834/",
    pdf = "https://aclanthology.org/2023.findings-acl.834.pdf",
    doi = "10.18653/v1/2023.findings-acl.834",
    pages = "13190--13206",
    abstract = "To date, most work on text simplification has focused on sentence-level inputs. Early attempts at document simplification merely applied these approaches iteratively over the sentences of a document. However, this fails to coherently preserve the discourse structure, leading to suboptimal output quality. Recently, strategies from controllable simplification have been leveraged to achieve state-of-the-art results on document simplification by first generating a document-level plan (a sequence of sentence-level simplification operations) and using this plan to guide sentence-level simplification downstream. However, this is still limited in that the simplification model has no direct access to the local inter-sentence document context, likely having a negative impact on surface realisation. We explore various systems that use document context within the simplification process itself, either by iterating over larger text units or by extending the system architecture to attend over a high-level representation of document context. In doing so, we achieve state-of-the-art performance on the document simplification task, even when not relying on plan-guidance. Further, we investigate the performance and efficiency tradeoffs of system variants and make suggestions of when each should be preferred.",
    selected={true},
}

@inproceedings{cripwell-etal-2023-document,
    abbr={EACL},
    title = "Document-Level Planning for Text Simplification",
    author = {Cripwell, Liam  and
      Legrand, Jo{\"e}l  and
      Gardent, Claire},
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.eacl-main.70",
    html={https://aclanthology.org/2023.eacl-main.70/},
    pdf={https://aclanthology.org/2023.eacl-main.70.pdf},
    pages = "993--1006",
    abstract="Most existing work on text simplification is limited to sentence-level inputs, with attempts to iteratively apply these approaches to document-level simplification failing to coherently preserve the discourse structure of the document. We hypothesise that by providing a high-level view of the target document, a simplification plan might help to guide generation. Building upon previous work on controlled, sentence-level simplification, we view a plan as a sequence of labels, each describing one of four sentence-level simplification operations (copy, rephrase, split, or delete). We propose a planning model that labels each sentence in the input document while considering both its context (a window of surrounding sentences) and its internal structure (a token-level representation). Experiments on two simplification benchmarks (Newsela-auto and Wiki-auto) show that our model outperforms strong baselines both on the planning task and when used to guide document-level simplification models.",
    selected={true},
}


@inproceedings{cripwell-etal-2022-controllable,
    abbr={NAACL},
    title = "Controllable Sentence Simplification via Operation Classification",
    author = {Cripwell, Liam  and
      Legrand, Jo{\"e}l  and
      Gardent, Claire},
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2022",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-naacl.161",
    html={https://aclanthology.org/2022.findings-naacl.161/},
    pdf={https://aclanthology.org/2022.findings-naacl.161.pdf},
    pages = "2091--2103",
    abstract = "Different types of transformations have been used to model sentence simplification ranging from mainly local operations such as phrasal or lexical rewriting, deletion and re-ordering to the more global affecting the whole input sentence such as sentence rephrasing, copying and splitting. In this paper, we propose a novel approach to sentence simplification which encompasses four global operations: whether to rephrase or copy and whether to split based on syntactic or discourse structure. We create a novel dataset that can be used to train highly accurate classification systems for these four operations. We propose a controllable-simplification model that tailors simplifications to these operations and show that it outperforms both end-to-end, non-controllable approaches and previous controllable approaches.",
    selected={true}
}


@inproceedings{cripwell-etal-2021-discourse-based,
  abbr={EMNLP},
  title = "Discourse-Based Sentence Splitting",
  author = {Cripwell, Liam  and
    Legrand, Jo{\"e}l  and
    Gardent, Claire},
  booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
  month = nov,
  year = "2021",
  address = "Punta Cana, Dominican Republic",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2021.findings-emnlp.25",
  pages = "261--273",
  html={https://aclanthology.org/2021.findings-emnlp.25},
  pdf={https://aclanthology.org/2021.findings-emnlp.25.pdf},
  abstract = "Sentence splitting involves the segmentation of a sentence into two or more shorter sentences. It is a key component of sentence simplification, has been shown to help human comprehension and is a useful preprocessing step for NLP tasks such as summarisation and relation extraction. While several methods and datasets have been proposed for developing sentence splitting models, little attention has been paid to how sentence splitting interacts with discourse structure. In this work, we focus on cases where the input text contains a discourse connective, which we refer to as discourse-based sentence splitting. We create synthetic and organic datasets for discourse-based splitting and explore different ways of combining these datasets using different model architectures. We show that pipeline models which use discourse structure to mediate sentence splitting outperform end-to-end models in learning the various ways of expressing a discourse relation but generate text that is less grammatical; that large scale synthetic data provides a better basis for learning than smaller scale organic data; and that training on discourse-focused, rather than on general sentence splitting data provides a better basis for discourse splitting.",
  selected={true}
}

@phdthesis{liamhonours,
  abbr        = {Honours Thesis},
  author      = {Cripwell, Liam},
  school      = {Queensland University of Technology (QUT)},
  title       = {Generating Clinical Queries from Patient Narratives},
  year        = {2017},
  pdf         = {honours_thesis.pdf}
}

@inproceedings{10.1145/3077136.3080661,
abbr={SIGIR},
author = {Koopman, Bevan and Cripwell, Liam and Zuccon, Guido},
title = {Generating Clinical Queries from Patient Narratives: A Comparison between Machines and Humans},
year = {2017},
isbn = {9781450350228},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3077136.3080661},
doi = {10.1145/3077136.3080661},
abstract = {This paper investigates how automated query generation methods can be used to derive effective ad-hoc queries from verbose patient narratives. In a clinical setting, automatic query generation provides a means of retrieving information relevant to a clinician, based on a patient record, but without the need for the clinician to manually author a query. Given verbose patient narratives, we evaluated a number of query reduction methods, both generic and domain specific. Comparison was made against human generated queries, both in terms of retrieval effectiveness and characteristics of human queries. Query reduction was an effective means of generating ad-hoc queries from narratives. However, human generated queries were still significantly more effective than automatically generated queries. Further improvements were possible if parameters of the query reduction methods were set on a per-query basis and a means of predicting this was developed. Under ideal conditions, automated methods can exceed humans. Effective human queries were found to contain many novel keywords not found in the narrative. Automated reduction methods may be handicapped in that they only use terms from narrative. Future work, therefore, may be directed toward better understanding effective human queries and automated query rewriting methods that attempt to model the inference of novel terms by exploiting semantic inference processes.},
booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {853â€“856},
numpages = {4},
keywords = {information retrieval, clinical search, query generation},
location = {Shinjuku, Tokyo, Japan},
series = {SIGIR '17},
html = {https://doi.org/10.1145/3077136.3080661},
pdf={http://ielab.io/publications/pdfs/koopman2017generating.pdf},
selected={false}
}

@article{Hussain2016PromotingUE,
  abbr={HISA},
  title={Promoting UV Exposure Awareness with Persuasive, Wearable Technologies},
  author={M. S. Hussain and Liam Cripwell and S. Berkovsky and J. Freyne},
  journal={Studies in health technology and informatics},
  year={2016},
  volume={227},
  pages={48-54},
  html = {https://www.semanticscholar.org/paper/Promoting-UV-Exposure-Awareness-with-Persuasive%2C-Hussain-Cripwell/0593beb4eef29c51fa1cb5414605fae3fa27574b?p2df},
  selected={false}
}